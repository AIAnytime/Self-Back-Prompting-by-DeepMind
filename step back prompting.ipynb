{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6566b39e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-28T11:11:00.890732Z",
     "start_time": "2023-10-28T11:10:39.001738Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting duckduckgo-search\n",
      "  Obtaining dependency information for duckduckgo-search from https://files.pythonhosted.org/packages/fb/fc/09e9dcb01ab3b872d911afddf27f98a9093692b34717dda8eb18b59c8a97/duckduckgo_search-3.9.3-py3-none-any.whl.metadata\n",
      "  Downloading duckduckgo_search-3.9.3-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting aiofiles>=23.2.1 (from duckduckgo-search)\n",
      "  Obtaining dependency information for aiofiles>=23.2.1 from https://files.pythonhosted.org/packages/c5/19/5af6804c4cc0fed83f47bff6e413a98a36618e7d40185cd36e69737f3b0e/aiofiles-23.2.1-py3-none-any.whl.metadata\n",
      "  Using cached aiofiles-23.2.1-py3-none-any.whl.metadata (9.7 kB)\n",
      "Collecting click>=8.1.7 (from duckduckgo-search)\n",
      "  Obtaining dependency information for click>=8.1.7 from https://files.pythonhosted.org/packages/00/2e/d53fa4befbf2cfa713304affc7ca780ce4fc1fd8710527771b58311a3229/click-8.1.7-py3-none-any.whl.metadata\n",
      "  Using cached click-8.1.7-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting lxml>=4.9.3 (from duckduckgo-search)\n",
      "  Obtaining dependency information for lxml>=4.9.3 from https://files.pythonhosted.org/packages/31/58/e3b3dd6bb2ab7404f1f4992e2d0e6926ed40cef8ce1b3bbefd95877499e1/lxml-4.9.3-cp311-cp311-win_amd64.whl.metadata\n",
      "  Downloading lxml-4.9.3-cp311-cp311-win_amd64.whl.metadata (3.9 kB)\n",
      "Collecting httpx[brotli,http2,socks]>=0.25.0 (from duckduckgo-search)\n",
      "  Obtaining dependency information for httpx[brotli,http2,socks]>=0.25.0 from https://files.pythonhosted.org/packages/33/0d/d9ce469af019741c8999711d36b270ff992ceb1a0293f73f9f34fdf131e9/httpx-0.25.0-py3-none-any.whl.metadata\n",
      "  Downloading httpx-0.25.0-py3-none-any.whl.metadata (7.6 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\aiany\\anaconda3\\lib\\site-packages (from click>=8.1.7->duckduckgo-search) (0.4.6)\n",
      "Requirement already satisfied: certifi in c:\\users\\aiany\\anaconda3\\lib\\site-packages (from httpx[brotli,http2,socks]>=0.25.0->duckduckgo-search) (2023.7.22)\n",
      "Collecting httpcore<0.19.0,>=0.18.0 (from httpx[brotli,http2,socks]>=0.25.0->duckduckgo-search)\n",
      "  Obtaining dependency information for httpcore<0.19.0,>=0.18.0 from https://files.pythonhosted.org/packages/ac/97/724afbb7925339f6214bf1fdb5714d1a462690466832bf8fb3fd497649f1/httpcore-0.18.0-py3-none-any.whl.metadata\n",
      "  Downloading httpcore-0.18.0-py3-none-any.whl.metadata (18 kB)\n",
      "Requirement already satisfied: idna in c:\\users\\aiany\\anaconda3\\lib\\site-packages (from httpx[brotli,http2,socks]>=0.25.0->duckduckgo-search) (3.4)\n",
      "Requirement already satisfied: sniffio in c:\\users\\aiany\\anaconda3\\lib\\site-packages (from httpx[brotli,http2,socks]>=0.25.0->duckduckgo-search) (1.2.0)\n",
      "Collecting brotli (from httpx[brotli,http2,socks]>=0.25.0->duckduckgo-search)\n",
      "  Obtaining dependency information for brotli from https://files.pythonhosted.org/packages/02/8a/fece0ee1057643cb2a5bbf59682de13f1725f8482b2c057d4e799d7ade75/Brotli-1.1.0-cp311-cp311-win_amd64.whl.metadata\n",
      "  Downloading Brotli-1.1.0-cp311-cp311-win_amd64.whl.metadata (5.6 kB)\n",
      "Collecting h2<5,>=3 (from httpx[brotli,http2,socks]>=0.25.0->duckduckgo-search)\n",
      "  Using cached h2-4.1.0-py3-none-any.whl (57 kB)\n",
      "Collecting socksio==1.* (from httpx[brotli,http2,socks]>=0.25.0->duckduckgo-search)\n",
      "  Downloading socksio-1.0.0-py3-none-any.whl (12 kB)\n",
      "Collecting hyperframe<7,>=6.0 (from h2<5,>=3->httpx[brotli,http2,socks]>=0.25.0->duckduckgo-search)\n",
      "  Using cached hyperframe-6.0.1-py3-none-any.whl (12 kB)\n",
      "Collecting hpack<5,>=4.0 (from h2<5,>=3->httpx[brotli,http2,socks]>=0.25.0->duckduckgo-search)\n",
      "  Using cached hpack-4.0.0-py3-none-any.whl (32 kB)\n",
      "Requirement already satisfied: anyio<5.0,>=3.0 in c:\\users\\aiany\\anaconda3\\lib\\site-packages (from httpcore<0.19.0,>=0.18.0->httpx[brotli,http2,socks]>=0.25.0->duckduckgo-search) (3.7.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\aiany\\anaconda3\\lib\\site-packages (from httpcore<0.19.0,>=0.18.0->httpx[brotli,http2,socks]>=0.25.0->duckduckgo-search) (0.14.0)\n",
      "Downloading duckduckgo_search-3.9.3-py3-none-any.whl (25 kB)\n",
      "Using cached aiofiles-23.2.1-py3-none-any.whl (15 kB)\n",
      "Using cached click-8.1.7-py3-none-any.whl (97 kB)\n",
      "Downloading lxml-4.9.3-cp311-cp311-win_amd64.whl (3.8 MB)\n",
      "   ---------------------------------------- 0.0/3.8 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.1/3.8 MB 5.5 MB/s eta 0:00:01\n",
      "   -- ------------------------------------- 0.2/3.8 MB 3.0 MB/s eta 0:00:02\n",
      "   -- ------------------------------------- 0.3/3.8 MB 2.6 MB/s eta 0:00:02\n",
      "   ---- ----------------------------------- 0.4/3.8 MB 2.6 MB/s eta 0:00:02\n",
      "   ---- ----------------------------------- 0.4/3.8 MB 2.6 MB/s eta 0:00:02\n",
      "   ---- ----------------------------------- 0.5/3.8 MB 2.1 MB/s eta 0:00:02\n",
      "   ------ --------------------------------- 0.6/3.8 MB 2.1 MB/s eta 0:00:02\n",
      "   ------- -------------------------------- 0.7/3.8 MB 1.9 MB/s eta 0:00:02\n",
      "   --------- ------------------------------ 0.9/3.8 MB 2.3 MB/s eta 0:00:02\n",
      "   ---------- ----------------------------- 1.0/3.8 MB 2.3 MB/s eta 0:00:02\n",
      "   ----------- ---------------------------- 1.1/3.8 MB 2.3 MB/s eta 0:00:02\n",
      "   ------------- -------------------------- 1.3/3.8 MB 2.4 MB/s eta 0:00:02\n",
      "   ---------------- ----------------------- 1.5/3.8 MB 2.6 MB/s eta 0:00:01\n",
      "   ----------------- ---------------------- 1.6/3.8 MB 2.6 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 1.9/3.8 MB 2.9 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 2.1/3.8 MB 2.9 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 2.3/3.8 MB 3.1 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 2.5/3.8 MB 3.2 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 2.8/3.8 MB 3.4 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 2.9/3.8 MB 3.2 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 3.3/3.8 MB 3.4 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 3.6/3.8 MB 3.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  3.8/3.8 MB 3.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 3.8/3.8 MB 3.5 MB/s eta 0:00:00\n",
      "Using cached httpcore-0.18.0-py3-none-any.whl (76 kB)\n",
      "Downloading Brotli-1.1.0-cp311-cp311-win_amd64.whl (357 kB)\n",
      "   ---------------------------------------- 0.0/357.3 kB ? eta -:--:--\n",
      "   ---- ----------------------------------- 41.0/357.3 kB ? eta -:--:--\n",
      "   ---------------------------------------- 357.3/357.3 kB 7.4 MB/s eta 0:00:00\n",
      "Using cached httpx-0.25.0-py3-none-any.whl (75 kB)\n",
      "Installing collected packages: brotli, socksio, lxml, hyperframe, hpack, click, aiofiles, httpcore, h2, httpx, duckduckgo-search\n",
      "  Attempting uninstall: lxml\n",
      "    Found existing installation: lxml 4.9.2\n",
      "    Uninstalling lxml-4.9.2:\n",
      "      Successfully uninstalled lxml-4.9.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not install packages due to an OSError: [WinError 5] Access is denied: 'C:\\\\Users\\\\aiany\\\\anaconda3\\\\Lib\\\\site-packages\\\\~xml\\\\etree.cp311-win_amd64.pyd'\n",
      "Consider using the `--user` option or check the permissions.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchainhub\n",
      "  Obtaining dependency information for langchainhub from https://files.pythonhosted.org/packages/e9/4c/25e098d3f43a57e3d0936ca09c4ad607fd40ac4b784072ccdbd4dfa55967/langchainhub-0.1.13-py3-none-any.whl.metadata\n",
      "  Downloading langchainhub-0.1.13-py3-none-any.whl.metadata (478 bytes)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\aiany\\anaconda3\\lib\\site-packages (from langchainhub) (2.31.0)\n",
      "Collecting types-requests<3.0.0.0,>=2.31.0.2 (from langchainhub)\n",
      "  Obtaining dependency information for types-requests<3.0.0.0,>=2.31.0.2 from https://files.pythonhosted.org/packages/1d/d6/1281c1d7b03a127562d6644ebff081e85045f0025b1fe26dcdd82811ad1a/types_requests-2.31.0.10-py3-none-any.whl.metadata\n",
      "  Downloading types_requests-2.31.0.10-py3-none-any.whl.metadata (1.8 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\aiany\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchainhub) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\aiany\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchainhub) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\aiany\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchainhub) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\aiany\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchainhub) (2023.7.22)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests<3,>=2->langchainhub)\n",
      "  Obtaining dependency information for urllib3<3,>=1.21.1 from https://files.pythonhosted.org/packages/d2/b2/b157855192a68541a91ba7b2bbcb91f1b4faa51f8bae38d8005c034be524/urllib3-2.0.7-py3-none-any.whl.metadata\n",
      "  Downloading urllib3-2.0.7-py3-none-any.whl.metadata (6.6 kB)\n",
      "Downloading langchainhub-0.1.13-py3-none-any.whl (3.4 kB)\n",
      "Downloading types_requests-2.31.0.10-py3-none-any.whl (14 kB)\n",
      "Using cached urllib3-2.0.7-py3-none-any.whl (124 kB)\n",
      "Installing collected packages: urllib3, types-requests, langchainhub\n",
      "  Attempting uninstall: urllib3\n",
      "    Found existing installation: urllib3 1.26.16\n",
      "    Uninstalling urllib3-1.26.16:\n",
      "      Successfully uninstalled urllib3-1.26.16\n",
      "Successfully installed langchainhub-0.1.13 types-requests-2.31.0.10 urllib3-2.0.7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "botocore 1.27.59 requires urllib3<1.27,>=1.25.4, but you have urllib3 2.0.7 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "!pip install duckduckgo-search\n",
    "!pip install langchainhub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8be617db",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-28T11:11:40.309267Z",
     "start_time": "2023-10-28T11:11:40.304730Z"
    }
   },
   "outputs": [],
   "source": [
    "from langchain.utilities import DuckDuckGoSearchAPIWrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "92b522e2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-28T11:12:03.628573Z",
     "start_time": "2023-10-28T11:12:03.624016Z"
    }
   },
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cd84e9f9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-28T11:12:24.113329Z",
     "start_time": "2023-10-28T11:12:24.108802Z"
    }
   },
   "outputs": [],
   "source": [
    "os.environ[\"OPENAI_API_KEY\"] = \"""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "878da8d7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-28T11:13:09.401289Z",
     "start_time": "2023-10-28T11:13:09.396735Z"
    }
   },
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate, FewShotChatMessagePromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6344e8bc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-28T11:15:14.123947Z",
     "start_time": "2023-10-28T11:15:14.119200Z"
    }
   },
   "outputs": [],
   "source": [
    "examples = [\n",
    "    {\n",
    "        \"input\": \"Can members of the police legally make arrests?\",\n",
    "        \"output\": \"What can members of the police do?\"\n",
    "    },\n",
    "    {\n",
    "        \"input\": \"In what country was Jan Schindel born?\",\n",
    "        \"output\": \"What is Jan Schindel's background?\"\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6343473e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-28T11:16:19.680925Z",
     "start_time": "2023-10-28T11:16:19.674731Z"
    }
   },
   "outputs": [],
   "source": [
    "example_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"human\", \"{input}\"),\n",
    "        (\"ai\", \"{output}\")\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c81e196c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-28T11:16:54.439292Z",
     "start_time": "2023-10-28T11:16:54.434631Z"
    }
   },
   "outputs": [],
   "source": [
    "few_shot_prompt = FewShotChatMessagePromptTemplate(\n",
    "    example_prompt= example_prompt,\n",
    "    examples= examples\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6f2c1378",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-28T11:19:30.033767Z",
     "start_time": "2023-10-28T11:19:30.028294Z"
    }
   },
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"\"\"You are an expert at world knowledge. Your task is to step back and paraphrase a question to a more generic step-back question, \n",
    "    which is easier to answer. here are a few examples:\"\"\"),\n",
    "    few_shot_prompt,\n",
    "    (\"user\", \"{question}\")\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7518438d",
   "metadata": {},
   "source": [
    "## Preparing the chain to generate stepback questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e33cf99f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-28T11:20:39.048945Z",
     "start_time": "2023-10-28T11:20:39.043656Z"
    }
   },
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.schema.output_parser import StrOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "febafa73",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-28T11:21:15.327686Z",
     "start_time": "2023-10-28T11:21:15.250570Z"
    }
   },
   "outputs": [],
   "source": [
    "question_gen = prompt | ChatOpenAI(temperature=0) | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cb0f656c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-28T11:21:19.918425Z",
     "start_time": "2023-10-28T11:21:19.906725Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RunnableSequence(first=ChatPromptTemplate(input_variables=['question'], output_parser=None, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], output_parser=None, partial_variables={}, template='You are an expert at world knowledge. Your task is to step back and paraphrase a question to a more generic step-back question, \\n    which is easier to answer. here are a few examples:', template_format='f-string', validate_template=True), additional_kwargs={}), FewShotChatMessagePromptTemplate(examples=[{'input': 'Can members of the police legally make arrests?', 'output': 'What can members of the police do?'}, {'input': 'In what country was Jan Schindel born?', 'output': \"What is Jan Schindel's background?\"}], example_selector=None, input_variables=[], output_parser=None, partial_variables={}, example_prompt=ChatPromptTemplate(input_variables=['input', 'output'], output_parser=None, partial_variables={}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], output_parser=None, partial_variables={}, template='{input}', template_format='f-string', validate_template=True), additional_kwargs={}), AIMessagePromptTemplate(prompt=PromptTemplate(input_variables=['output'], output_parser=None, partial_variables={}, template='{output}', template_format='f-string', validate_template=True), additional_kwargs={})])), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['question'], output_parser=None, partial_variables={}, template='{question}', template_format='f-string', validate_template=True), additional_kwargs={})]), middle=[ChatOpenAI(cache=None, verbose=False, callbacks=None, callback_manager=None, tags=None, metadata=None, client=<class 'openai.api_resources.chat_completion.ChatCompletion'>, model_name='gpt-3.5-turbo', temperature=0.0, model_kwargs={}, openai_api_key='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', openai_api_base='', openai_organization='', openai_proxy='', request_timeout=None, max_retries=6, streaming=False, n=1, max_tokens=None, tiktoken_model_name=None)], last=StrOutputParser())"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question_gen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "072505a5",
   "metadata": {},
   "source": [
    "## Generate stepback questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "a837bf7a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-28T11:50:06.719066Z",
     "start_time": "2023-10-28T11:50:06.713241Z"
    }
   },
   "outputs": [],
   "source": [
    "question = \"Who won the 2022-2023 English Premier League Trophy?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "2f12fcfe",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-28T11:50:09.354900Z",
     "start_time": "2023-10-28T11:50:07.288458Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Who was the champion of the English Premier League in the 2022-2023 season?'"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question_gen.invoke({\"question\": question})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a936cd56",
   "metadata": {},
   "source": [
    "## Retriever to collect info from web search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5deac401",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-28T11:24:08.414171Z",
     "start_time": "2023-10-28T11:24:01.573407Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting duckduckgo-search\n",
      "  Obtaining dependency information for duckduckgo-search from https://files.pythonhosted.org/packages/fb/fc/09e9dcb01ab3b872d911afddf27f98a9093692b34717dda8eb18b59c8a97/duckduckgo_search-3.9.3-py3-none-any.whl.metadata\n",
      "  Using cached duckduckgo_search-3.9.3-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting aiofiles>=23.2.1 (from duckduckgo-search)\n",
      "  Obtaining dependency information for aiofiles>=23.2.1 from https://files.pythonhosted.org/packages/c5/19/5af6804c4cc0fed83f47bff6e413a98a36618e7d40185cd36e69737f3b0e/aiofiles-23.2.1-py3-none-any.whl.metadata\n",
      "  Using cached aiofiles-23.2.1-py3-none-any.whl.metadata (9.7 kB)\n",
      "Collecting click>=8.1.7 (from duckduckgo-search)\n",
      "  Obtaining dependency information for click>=8.1.7 from https://files.pythonhosted.org/packages/00/2e/d53fa4befbf2cfa713304affc7ca780ce4fc1fd8710527771b58311a3229/click-8.1.7-py3-none-any.whl.metadata\n",
      "  Using cached click-8.1.7-py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: lxml>=4.9.3 in c:\\users\\aiany\\anaconda3\\lib\\site-packages (from duckduckgo-search) (4.9.3)\n",
      "Collecting httpx[brotli,http2,socks]>=0.25.0 (from duckduckgo-search)\n",
      "  Obtaining dependency information for httpx[brotli,http2,socks]>=0.25.0 from https://files.pythonhosted.org/packages/33/0d/d9ce469af019741c8999711d36b270ff992ceb1a0293f73f9f34fdf131e9/httpx-0.25.0-py3-none-any.whl.metadata\n",
      "  Using cached httpx-0.25.0-py3-none-any.whl.metadata (7.6 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\aiany\\anaconda3\\lib\\site-packages (from click>=8.1.7->duckduckgo-search) (0.4.6)\n",
      "Requirement already satisfied: certifi in c:\\users\\aiany\\anaconda3\\lib\\site-packages (from httpx[brotli,http2,socks]>=0.25.0->duckduckgo-search) (2023.7.22)\n",
      "Collecting httpcore<0.19.0,>=0.18.0 (from httpx[brotli,http2,socks]>=0.25.0->duckduckgo-search)\n",
      "  Obtaining dependency information for httpcore<0.19.0,>=0.18.0 from https://files.pythonhosted.org/packages/ac/97/724afbb7925339f6214bf1fdb5714d1a462690466832bf8fb3fd497649f1/httpcore-0.18.0-py3-none-any.whl.metadata\n",
      "  Using cached httpcore-0.18.0-py3-none-any.whl.metadata (18 kB)\n",
      "Requirement already satisfied: idna in c:\\users\\aiany\\anaconda3\\lib\\site-packages (from httpx[brotli,http2,socks]>=0.25.0->duckduckgo-search) (3.4)\n",
      "Requirement already satisfied: sniffio in c:\\users\\aiany\\anaconda3\\lib\\site-packages (from httpx[brotli,http2,socks]>=0.25.0->duckduckgo-search) (1.2.0)\n",
      "Requirement already satisfied: brotli in c:\\users\\aiany\\anaconda3\\lib\\site-packages (from httpx[brotli,http2,socks]>=0.25.0->duckduckgo-search) (1.1.0)\n",
      "Collecting h2<5,>=3 (from httpx[brotli,http2,socks]>=0.25.0->duckduckgo-search)\n",
      "  Using cached h2-4.1.0-py3-none-any.whl (57 kB)\n",
      "Requirement already satisfied: socksio==1.* in c:\\users\\aiany\\anaconda3\\lib\\site-packages (from httpx[brotli,http2,socks]>=0.25.0->duckduckgo-search) (1.0.0)\n",
      "Collecting hyperframe<7,>=6.0 (from h2<5,>=3->httpx[brotli,http2,socks]>=0.25.0->duckduckgo-search)\n",
      "  Using cached hyperframe-6.0.1-py3-none-any.whl (12 kB)\n",
      "Collecting hpack<5,>=4.0 (from h2<5,>=3->httpx[brotli,http2,socks]>=0.25.0->duckduckgo-search)\n",
      "  Using cached hpack-4.0.0-py3-none-any.whl (32 kB)\n",
      "Requirement already satisfied: anyio<5.0,>=3.0 in c:\\users\\aiany\\anaconda3\\lib\\site-packages (from httpcore<0.19.0,>=0.18.0->httpx[brotli,http2,socks]>=0.25.0->duckduckgo-search) (3.7.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\aiany\\anaconda3\\lib\\site-packages (from httpcore<0.19.0,>=0.18.0->httpx[brotli,http2,socks]>=0.25.0->duckduckgo-search) (0.14.0)\n",
      "Using cached duckduckgo_search-3.9.3-py3-none-any.whl (25 kB)\n",
      "Using cached aiofiles-23.2.1-py3-none-any.whl (15 kB)\n",
      "Using cached click-8.1.7-py3-none-any.whl (97 kB)\n",
      "Using cached httpcore-0.18.0-py3-none-any.whl (76 kB)\n",
      "Using cached httpx-0.25.0-py3-none-any.whl (75 kB)\n",
      "Installing collected packages: hyperframe, hpack, click, aiofiles, httpcore, h2, httpx, duckduckgo-search\n",
      "  Attempting uninstall: click\n",
      "    Found existing installation: click 8.0.4\n",
      "    Uninstalling click-8.0.4:\n",
      "      Successfully uninstalled click-8.0.4\n",
      "  Attempting uninstall: aiofiles\n",
      "    Found existing installation: aiofiles 22.1.0\n",
      "    Uninstalling aiofiles-22.1.0:\n",
      "      Successfully uninstalled aiofiles-22.1.0\n",
      "Successfully installed aiofiles-23.2.1 click-8.1.7 duckduckgo-search-3.9.3 h2-4.1.0 hpack-4.0.0 httpcore-0.18.0 httpx-0.25.0 hyperframe-6.0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "python-lsp-black 1.2.1 requires black>=22.3.0, but you have black 0.0 which is incompatible.\n",
      "ypy-websocket 0.8.2 requires aiofiles<23,>=22.1.0, but you have aiofiles 23.2.1 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "!pip install duckduckgo-search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "08bbce68",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-28T11:50:15.945295Z",
     "start_time": "2023-10-28T11:50:15.940619Z"
    }
   },
   "outputs": [],
   "source": [
    "search = DuckDuckGoSearchAPIWrapper(max_results=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "ae8aa19d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-28T11:50:16.989579Z",
     "start_time": "2023-10-28T11:50:16.984376Z"
    }
   },
   "outputs": [],
   "source": [
    "def retriever(query):\n",
    "    return search.run(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "ca06ef8d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-28T11:50:18.994727Z",
     "start_time": "2023-10-28T11:50:17.603994Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"When Man City became 2022/23 champions as Forest won Man City's best goals of 2022/23 The Premier League Trophy is the ultimate prize that teams battle for over 38 matches. But did you know that there is in fact more than one Trophy? Here are some key facts about the Premier League Trophy and medals. Two Trophies Manchester City are the 2022/23 Premier League champions after a 1-0 defeat for Arsenal at Nottingham Forest means that Pep Guardiola 's side can no longer be caught at the top of the table. An early goal from Taiwo Awoniyi was enough for Forest to beat Arsenal and put them four points behind the leaders with only one match to play. Manchester City celebrated their position as the 2022/23 Premier League champions, lifting the Trophy after a 1-0 win over Chelsea. The Man City squad and backroom staff received the Trophy, medals and the accolade of fans at the Etihad Stadium after the match, which was won thanks to Julian Alvarez 's first-half strike. Manchester City crowned 2022-23 Premier League champions, win third-straight title By Joe Prince-Wright Published May 22, 2023 07:20 AM Manchester City have been crowned Premier League champions for the 2022-23 season as Pep Guardiola's side completed the three-peat. [ MORE: Video, highlights, interviews from Man City's title celebrations ] OLI SCARFFAFP Manchester City were crowned Premier League champions for the 2022/23 season, their third in a row, after Arsenal lost to Nottingham Forest, who also secured their status as a... By Jude Summerfield | May 21, 2023. Manchester City lifted the Premier League trophy on Sunday afternoon following their 1-0 victory over Chelsea. Nottingham Forest's win over Arsenal on Saturday ...\""
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "c4949b32",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-28T11:50:25.468843Z",
     "start_time": "2023-10-28T11:50:21.417781Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Ben Miller â€¢ 20 min read The final day of the 2022/23 Premier League season started with three teams hoping to avoid the final two relegation places. The group was separated by just two... The Premier League winners have been determined for the 2022-23 season as en epic title battle played out and Manchester City finished ahead of Arsenal to seal a third-straight title. With Manchester City hunting down Arsenal in the final months of the current campaign, it made you think back to some of the great teams, and champs, in years ... Under the tutelage of Roberto de Zerbi, left-back Pervis Estupinan has come into his own this season and has bagged an impressive six assists to his name in the Premier League. Estupinan has... Burnley's rise back to the Premier League comes after a massive summer overhaul that saw club stalwarts James Tarkowski and Nick Pope depart, with Kompany managing to integrate 16 new signings. The verdicts of the 2022/23 Premier League season are final as Manchester City were crowned champions, the top 7 will be heading into Europe, and the bottom three are going down. It was a... Joe Prince-Wright Published May 22, 2023 07:20 AM Manchester City have been crowned Premier League champions for the 2022-23 season as Pep Guardiola's side completed the three-peat. [ MORE: Video, highlights, interviews from Man City's title celebrations ]\""
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever(question_gen.invoke({\"question\": question}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "ffb6dbac",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-28T11:50:26.832038Z",
     "start_time": "2023-10-28T11:50:26.827484Z"
    }
   },
   "outputs": [],
   "source": [
    "from langchain import hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "bafe1db7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-28T11:50:30.666666Z",
     "start_time": "2023-10-28T11:50:29.267613Z"
    }
   },
   "outputs": [],
   "source": [
    "response_prompt = hub.pull(\"langchain-ai/stepback-answer\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fec37b3d",
   "metadata": {},
   "source": [
    "## Prepare a chain that uses the \"stepback answer\" prompt template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "ee2f8128",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-28T11:50:31.158807Z",
     "start_time": "2023-10-28T11:50:31.153433Z"
    }
   },
   "outputs": [],
   "source": [
    "from langchain.schema.runnable import RunnableLambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "4f497ee9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-28T11:50:31.904436Z",
     "start_time": "2023-10-28T11:50:31.898942Z"
    }
   },
   "outputs": [],
   "source": [
    "chain = {\n",
    "    \"normal_context\": RunnableLambda(lambda x:x['question']) | retriever,\n",
    "    \"step_back_context\": question_gen | retriever,\n",
    "    \"question\": lambda x: x[\"question\"]\n",
    "} | response_prompt | ChatOpenAI(temperature=0) | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "f1c83292",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-28T11:50:33.367920Z",
     "start_time": "2023-10-28T11:50:33.360848Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RunnableSequence(first=RunnableMap(steps={'normal_context': RunnableSequence(first=RunnableLambda(...), middle=[], last=RunnableLambda(...)), 'step_back_context': RunnableSequence(first=ChatPromptTemplate(input_variables=['question'], output_parser=None, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], output_parser=None, partial_variables={}, template='You are an expert at world knowledge. Your task is to step back and paraphrase a question to a more generic step-back question, \\n    which is easier to answer. here are a few examples:', template_format='f-string', validate_template=True), additional_kwargs={}), FewShotChatMessagePromptTemplate(examples=[{'input': 'Can members of the police legally make arrests?', 'output': 'What can members of the police do?'}, {'input': 'In what country was Jan Schindel born?', 'output': \"What is Jan Schindel's background?\"}], example_selector=None, input_variables=[], output_parser=None, partial_variables={}, example_prompt=ChatPromptTemplate(input_variables=['input', 'output'], output_parser=None, partial_variables={}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], output_parser=None, partial_variables={}, template='{input}', template_format='f-string', validate_template=True), additional_kwargs={}), AIMessagePromptTemplate(prompt=PromptTemplate(input_variables=['output'], output_parser=None, partial_variables={}, template='{output}', template_format='f-string', validate_template=True), additional_kwargs={})])), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['question'], output_parser=None, partial_variables={}, template='{question}', template_format='f-string', validate_template=True), additional_kwargs={})]), middle=[ChatOpenAI(cache=None, verbose=False, callbacks=None, callback_manager=None, tags=None, metadata=None, client=<class 'openai.api_resources.chat_completion.ChatCompletion'>, model_name='gpt-3.5-turbo', temperature=0.0, model_kwargs={}, openai_api_key='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', openai_api_base='', openai_organization='', openai_proxy='', request_timeout=None, max_retries=6, streaming=False, n=1, max_tokens=None, tiktoken_model_name=None), StrOutputParser()], last=RunnableLambda(...)), 'question': RunnableLambda(...)}), middle=[PromptTemplate(input_variables=['normal_context', 'step_back_context', 'question'], output_parser=None, partial_variables={}, template='You are an expert of world knowledge. I am going to ask you a question. Your response should be comprehensive and not contradicted with the following context if they are relevant. Otherwise, ignore them if they are not relevant.\\n\\n{normal_context}\\n{step_back_context}\\n\\nOriginal Question: {question}\\nAnswer:', template_format='f-string', validate_template=True), ChatOpenAI(cache=None, verbose=False, callbacks=None, callback_manager=None, tags=None, metadata=None, client=<class 'openai.api_resources.chat_completion.ChatCompletion'>, model_name='gpt-3.5-turbo', temperature=0.0, model_kwargs={}, openai_api_key='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', openai_api_base='', openai_organization='', openai_proxy='', request_timeout=None, max_retries=6, streaming=False, n=1, max_tokens=None, tiktoken_model_name=None)], last=StrOutputParser())"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "2231811a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-28T11:50:53.023323Z",
     "start_time": "2023-10-28T11:50:34.025332Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Manchester City won the 2022-2023 English Premier League Trophy. They were crowned champions for the third consecutive season after a 1-0 defeat for Arsenal at Nottingham Forest. This victory secured Manchester City's status as the Premier League champions, as they could no longer be caught at the top of the table. The winning goal in the decisive match was scored by Taiwo Awoniyi of Nottingham Forest. Manchester City celebrated their title by lifting the Premier League Trophy after a 1-0 win over Chelsea. The squad and backroom staff received the Trophy, medals, and the adulation of the fans at the Etihad Stadium. This is Manchester City's fifth Premier League title overall.\""
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"question\": question})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e59c879d",
   "metadata": {},
   "source": [
    "## if you don't step back"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "3d68477b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-28T11:51:04.172605Z",
     "start_time": "2023-10-28T11:51:04.168249Z"
    }
   },
   "outputs": [],
   "source": [
    "response_prompt_template = \"\"\"You are an expert of world knowledge. I am going to ask you a question. \n",
    "Your response should be comprehensive and not contradicted with the following context if they are relevant. \n",
    "Otherwise, ignore them if they are not relevant.\n",
    "{normal_context}\n",
    "\n",
    "Original Question: {question}\n",
    "Answer:\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "430ef306",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-28T11:51:04.771878Z",
     "start_time": "2023-10-28T11:51:04.767205Z"
    }
   },
   "outputs": [],
   "source": [
    "response_prompt = ChatPromptTemplate.from_template(response_prompt_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "51424ef6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-28T11:51:05.623675Z",
     "start_time": "2023-10-28T11:51:05.617788Z"
    }
   },
   "outputs": [],
   "source": [
    "chain = {\n",
    "    \"normal_context\": RunnableLambda(lambda x:x['question']) | retriever,\n",
    "    \"question\": lambda x: x[\"question\"]\n",
    "} | response_prompt | ChatOpenAI(temperature=0) | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "12f3f165",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-28T11:51:12.772338Z",
     "start_time": "2023-10-28T11:51:06.188025Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Manchester City won the 2022-2023 English Premier League Trophy.'"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"question\": question})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a8172e2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
